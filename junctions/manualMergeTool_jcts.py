
# External imports

import pandas as pd

import datetime

# Internal imports

# (1) Utils:
#     In this script, we'll require from utils functionality that ensures all files (.csv, .html)
#     will be written to the junctions subdirectory and not its parent directory.

import sys
sys.path.append("..")

import utils

# (2) Manual cluster preparation tool:
#     Provides the data required for manual cluster correction.
#     This data indicates where clustering solutions differ between buffers, i.e. where merges have
#     taken place when utilizing a rather liberal buffer parameter (e.g., 3) but not when utilizing a 
#     more conservative one (e.g., 2).
#     2 and 3 as conservative resp. liberal buffer parameter will work in most cases; consider increasing
#     resp. decreasing them by 0.5 each for particularly narrow resp. wide city layouts.
#     
#     In this script, we do not only use the data generated by manualClusterPrep but also call one of its
#     functions directly:
#     * plotPrep: polygon shapes of junctions in the same cluster are dissolved, i.e. melted together;
#                 the remaining columns are also aggregated by cluster. (Naturally, these operations
#                 are only performed for the 'non-isolated junctions', i.e. those whose polygon surfaces
#                 overlap with those of other junctions) 

import manualMergePrep_jcts as manualMergePrep

# (3) Mapping tool as helper for manual cluster correction:
#     Differs from the standard mapping tool used by the main script (OSM_Jcts) with respect to the following aspects:
#     - inconsistent clusters (where merges have taken place with a liberal, but not a conservative buffer)
#       are highlighted in yellow.
#     - markers are attached to polygons; upon click, the respective cluster-nr. is displayed. This way,
#       a manual merge can be performed via CLI by specifying the to-be-merged cluster nrs.

import mapJcts_clustAssist_jcts as mapping

# (4) Data tidying tool for junctions:
#     This is the exact same script used by the main script (OSM_Jcts). Here, it helps with
#     - dealing with multi-polygons which may have emerged during cluster merges
#     - aligning the columns in the data frame containing non-isolated junctions (which have been clustered and merged
#       together) and isolated junctions (whose polygon surfaces don't overlap with those of any other junctions
#       and which hence have not been merged with any other junctions),
#     - and finally merging the two dfs together. 

import tidyData_Jcts

def update_clust(small_buf_clstrs, large_buf_clstr, region):

    # (1) read small_buf_inconsist pickle

    small_buf_inconsist_path = utils.getSubDirPath(f"jcts_small_buf_inconsist_{region}", "pickled_data", "junctions")

    small_buf_inconsist = pd.read_pickle(small_buf_inconsist_path)

    # (2) read large_buf_inconsist pickle

    large_buf_inconsist_path = utils.getSubDirPath(f"jcts_large_buf_inconsist_{region}", "pickled_data", "junctions")

    large_buf_inconsist = pd.read_pickle(large_buf_inconsist_path)

    # (3) read consistent clusters pickle

    consistent_clusters_path = utils.getSubDirPath(f"jcts_consistent_clusters_{region}", "pickled_data", "junctions")

    consistent_clusters = pd.read_pickle(consistent_clusters_path)

    # 'small_buf_clstrs' is a list of clusters having emerged in the small_buf-solution; remove the rows
    # corresponding to these clusters from 'small_buf_inconsist' as the large_buf-solution for the same
    # clustering problem is preferred as per user input. Accordingly, RESOLVE the conflict between the
    # small_buf- and large_buf-solutions by deleting the small_buf one and adding the large_buf one to our df 
    # containing the 'consistent_clusters'.

    # Delete the rejected cluster solution from 'small_buf_inconsist'

    for clust in small_buf_clstrs:

        small_buf_inconsist = small_buf_inconsist[small_buf_inconsist['neighbour_cluster'] != clust]

    # Grab the accepted solution from 'large_buf_inconsist'

    accepted_solution = large_buf_inconsist.loc[large_buf_inconsist['neighbour_cluster'] == large_buf_clstr].copy()

    # Set 'neighbour_cluster' to 999999 to make manual editing obvious and facilitate highlighting on map

    accepted_solution['neighbour_cluster'] = 999999

    large_buf_inconsist.loc[large_buf_inconsist['neighbour_cluster'] == large_buf_clstr, ['neighbour_cluster']] = 999999

    # Append accepted solution to 'consistent_clusters'

    consistent_clusters = pd.concat([consistent_clusters, accepted_solution], ignore_index = True, sort = False)

    mapping.runAllMapTasks(region, small_buf_inconsist, large_buf_inconsist)

    # Pickle the three data sets for further editing.

    # Write small_buf_inconsist pickle

    small_buf_inconsist.to_pickle(small_buf_inconsist_path)

    # Write large_buf_inconsist pickle

    large_buf_inconsist.to_pickle(large_buf_inconsist_path)

    # Write consistent clusters pickle

    consistent_clusters.to_pickle(consistent_clusters_path) 

# NEW 13/01/2021: allow not only replacement of more conservative clusters by more liberal ones, but also
#                 the deletion of conservative clusters.

def delete_clust(small_buf_clstr, region):

    # (1) read small_buf_inconsist pickle

    small_buf_inconsist_path = utils.getSubDirPath(f"jcts_small_buf_inconsist_{region}", "pickled_data", "junctions")

    small_buf_inconsist = pd.read_pickle(small_buf_inconsist_path)

    # (2) read large_buf_inconsist pickle

    large_buf_inconsist_path = utils.getSubDirPath(f"jcts_large_buf_inconsist_{region}", "pickled_data", "junctions")

    large_buf_inconsist = pd.read_pickle(large_buf_inconsist_path)

    # Delete the specified cluster

    small_buf_inconsist = small_buf_inconsist[small_buf_inconsist['neighbour_cluster'] != small_buf_clstr]

    small_buf_inconsist.to_pickle(small_buf_inconsist_path)

    # Draw a new map

    mapping.runAllMapTasks(region, small_buf_inconsist, large_buf_inconsist)
    
# Once editing is finished, write the resultant data - i.e., 
# a) the clusters that were consistent between the two dfs all along, 
# b) the conservative clusters that weren't deleted or replaced and thus remain in
#    the small_buf_inconsist df, 
# c) the more liberal clusters that were chosen to replace their more conservative counterparts and 
#    thus added to the consistent_cluster data.

def save_result (region):

    # (1) read small_buf_inconsist pickle

    small_buf_inconsist_path = utils.getSubDirPath(f"jcts_small_buf_inconsist_{region}", "pickled_data", "junctions")

    small_buf_accepted = pd.read_pickle(small_buf_inconsist_path)

    # (2) read consistent clusters pickle

    consistent_clusters_path = utils.getSubDirPath(f"jcts_consistent_clusters_{region}", "pickled_data", "junctions")

    consistent_plus_accepted_large_solutions = pd.read_pickle(consistent_clusters_path)

    complete_df = pd.concat([small_buf_accepted, consistent_plus_accepted_large_solutions], ignore_index = True, sort = False)

    file_name = f'manual_merging_res_{region}_{datetime.date.today()}.csv'

    path = utils.getSubDirPath(file_name, 'csv_data', 'junctions')

    complete_df.to_csv(path, index=False, sep="|")



